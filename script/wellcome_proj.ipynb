{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599264812268",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, ParameterGrid, validation_curve, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import pingouin as pg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking missing value \n",
    "def missing_val(df):\n",
    "    d = df.isna().sum().to_dict()\n",
    "    missing_k = [] \n",
    "    missing_v = []\n",
    "    missing_p = []\n",
    "    for k, v in d.items():\n",
    "        if v > 0:\n",
    "            missing_k.append(k)\n",
    "            missing_v.append(v)\n",
    "        else:\n",
    "            continue\n",
    "    for v in d.values():\n",
    "        if v > 0:\n",
    "            per = round((v/len(df) * 100), 4)\n",
    "            missing_p.append(per)\n",
    "        else:\n",
    "            continue\n",
    "    missing_df = pd.DataFrame(data=zip(missing_k, missing_v, missing_p), columns=['Column', 'Total Nulll', 'Missing %'])\n",
    "    return missing_df\n",
    "\n",
    "def save_csv(df, fname):\n",
    "    df.to_csv('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/csv_data/Wellcome/' + fname, index=False)\n",
    "\n",
    "def open_csv(fname):\n",
    "    df = pd.read_csv('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/csv_data/Wellcome/' + fname)\n",
    "    return df\n",
    "\n",
    "# Create factor analysis with loadings\n",
    "def factor_analysis(df, factor_num):\n",
    "    fa = FactorAnalyzer(factor_num, rotation='varimax')\n",
    "    fa.fit(df)\n",
    "    loads = fa.loadings_\n",
    "    ev, v = fa.get_eigenvalues()\n",
    "    return (loads, ev, v)\n",
    "\n",
    "# Create top 5 variables in each factor\n",
    "def factor_dataframe (df, loads):\n",
    "    factors = ['Factor ' + str(i) for i in range(1, (loads.shape[1] + 1))]\n",
    "    fadf = pd.DataFrame(data=loads, columns=factors)\n",
    "    fadf.insert(loc=0, column='VAR', value=df.columns)\n",
    "    for i in range (1, (loads.shape[1] + 1)):\n",
    "        factor_top5 = fadf.sort_values(by='Factor ' + str(i), ascending=False)[['VAR','Factor ' + str(i)]].iloc[:5]\n",
    "        factor_top5.set_index('VAR', inplace=True) \n",
    "        print('\\n')\n",
    "        print(factor_top5)\n",
    "\n",
    "# Create scree plot\n",
    "def factor_plot(df, ev, fname):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.scatter(range(1,df.shape[1]+1),ev)\n",
    "    plt.plot(range(1,df.shape[1]+1),ev)\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('Factors')\n",
    "    plt.ylabel('Eigenvalue')\n",
    "    plt.grid()\n",
    "    fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/' + fname)\n",
    "\n",
    "def idx_dev(df):\n",
    "    df = df.loc[:, ['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF']]\n",
    "    df = df[(df['VAC_IMPTCH'] != 99) & (df['VAC_SF'] != 99) & (df['VAC_EFF'] != 99)]\n",
    "    # Factor Analysis\n",
    "    # Insert prepared dataframe (must not contain single unique value/Null in each column), number of factors, and loads\n",
    "    loads, ev, v = factor_analysis(df, 1)\n",
    "    factor_dataframe(df, loads)\n",
    "\n",
    "    # Cronbach Alpha test\n",
    "    factor = df[['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF']]\n",
    "    factor_alpha = pg.cronbach_alpha(factor)\n",
    "    print(factor_alpha)\n",
    "\n",
    "# Check abnormal data for each country\n",
    "def check_ctry(col):\n",
    "    ndf = pd.DataFrame()\n",
    "    ndf['Country'] = df[df[col].isna()]['CTRY'].unique()\n",
    "    ndf = ndf.replace(country)\n",
    "    ndf['Country Code'] = df[df[col].isna()]['CTRY'].unique()\n",
    "    ndf =ndf.sort_values(by=['Country']).reset_index(drop=True)\n",
    "    return ndf\n",
    "\n",
    "# Check if a country have all missing value for certain variable. Abnormal means the country has all missing values for that variable, normal means the country only have a portion of missing values for that variable.\n",
    "def check_ctry_unique(ndf, var):\n",
    "    df = open_csv('full_data.csv')\n",
    "    normal_ctry = []\n",
    "    notnormal_ctry = []\n",
    "    for ctry in ndf['Country Code']:\n",
    "        missing = df[df['CTRY'] == ctry][var].unique()\n",
    "        if len(missing) <= 1:\n",
    "            notnormal_ctry.append(ctry)\n",
    "        else:\n",
    "            normal_ctry.append(ctry)\n",
    "    mapnormal = [country.get(item, item) for item in normal_ctry]\n",
    "    mapabnormal = [country.get(item, item) for item in notnormal_ctry] \n",
    "    return (normal_ctry, mapnormal, notnormal_ctry, mapabnormal)\n",
    "\n",
    "# Assign age category\n",
    "def age_category(df):\n",
    "    for idx, row in df[df['AGE_CAT'].isna()].iterrows():\n",
    "        if 15 <= df.loc[idx, 'AGE'] <= 29:\n",
    "            df.loc[idx, 'AGE_CAT'] = 1\n",
    "        elif 30 <= df.loc[idx, 'AGE'] <= 49:\n",
    "            df.loc[idx, 'AGE_CAT'] = 2\n",
    "        else:\n",
    "            df.loc[idx, 'AGE_CAT'] = 3\n",
    "    return df\n",
    "\n",
    "# Check train and test percentage\n",
    "def calculate_percentage(df1, df2):\n",
    "    return len(df1)/ (len(df2) + len(df1)) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_excel('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/excel_data/full_data.xlsx')\n",
    "# df.to_csv('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/csv_data/full_data.csv', index=False)\n",
    "\n",
    "# Replace all empty cell with NaN\n",
    "df = df.replace(' ', np.NaN)\n",
    "\n",
    "# # Change Data Type\n",
    "df['TRUSCI_IDX'] = df['TRUSCI_IDX'].astype('float64')\n",
    "df.info()\n",
    "print('\\n', '-- Dtypes Count --', '\\n', df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Data\n",
    "df = open_csv('full_data.csv')\n",
    "df.info()\n",
    "print('\\n', '-- Dtypes Count --', '\\n', df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset \n",
    "df = open_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAT_WGT, POP_WGT, FLD_DATE, YEAR\n",
    "df = df.drop(['NAT_WGT', 'POP_WGT', 'FLD_DATE', 'YEAR'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute SC_SS and SC_UNI with 97 since if no attended antecedent school means no next level schooling\n",
    "for idx, row in df[df['SC_PS'] == 97][['SC_SS', 'SC_UNI']].iterrows():\n",
    "    df.loc[idx, ['SC_SS', 'SC_UNI']] = 97\n",
    "\n",
    "for idx, row in df[df['SC_SS'] == 97][['SC_UNI']].iterrows():\n",
    "    df.loc[idx, ['SC_UNI']] = 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute TRUSCI_INX by replacing NA with 0\n",
    "for idx, row in df[df['TRUSCI_IDX'].isna()].iterrows():\n",
    "    df.loc[idx, ['TRUSCI_IDX']] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop VAC_IMPTCH, VAC_SF, and VAC_EFF with NA since we are interested on the attitude of those who know vaccine only\n",
    "df = df.dropna(subset=['VAC_IMPTCH'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop ANY_CH with NA\n",
    "df = df.dropna(subset=['ANY_CH'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop TRU_NATGOV, TRU_GOVADV, RELIG, SC_DISRELIG, BLV_SCRELIG, HHI\n",
    "df = df.drop(['TRU_NATGOV', 'TRU_GOVADV', 'RELIG', 'SC_DISRELIG', 'BLV_SCRELIG', 'HHI'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Northern Cyprus\n",
    "df = df.drop(df.loc[df['CTRY']==202].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into with child (with CH_RVAC) and no child (without CH_RVAC)\n",
    "df_ch = df.dropna(subset=['CH_RVAC'], how='all')\n",
    "df_noch = df[df['CH_RVAC'].isna()].drop(['ANY_CH','CH_RVAC'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set before preprocessing\n",
    "train_ch = df_ch.sample(frac=0.8, random_state=32)\n",
    "test_ch = df_ch.drop(train_ch.index)\n",
    "train_noch = df_noch.sample(frac=0.8, random_state=32)\n",
    "test_noch = df_noch.drop(train_noch.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save initial pre-processed data\n",
    "save_csv(df, 'fpp_df.csv')\n",
    "save_csv(df_ch, 'df_ch.csv')\n",
    "save_csv(df_noch, 'df_noch.csv')\n",
    "save_csv(train_ch.reset_index(drop=True), 'train_ch.csv')\n",
    "save_csv(test_ch.reset_index(drop=True), 'test_ch.csv')\n",
    "save_csv(train_noch.reset_index(drop=True), 'train_noch.csv')\n",
    "save_csv(test_noch.reset_index(drop=True), 'test_noch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After imputed AGE, EDU, LIV_AR, HHI, and EMP_STAT\n",
    "imptrain_ch = open_csv('imptrain_ch.csv')\n",
    "imptest_ch = open_csv('imptest_ch.csv')\n",
    "imptrain_noch = open_csv('imptrain_noch.csv')\n",
    "imptest_noch = open_csv('imptest_noch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign age into category to impute AGE_CAT\n",
    "imptrain_ch = age_category(imptrain_ch)\n",
    "imptest_ch = age_category(imptest_ch)\n",
    "imptrain_noch = age_category(imptrain_noch)\n",
    "imptest_noch = age_category(imptest_noch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change data type for AGE_CAT\n",
    "imptrain_ch['AGE_CAT'] = imptrain_ch['AGE_CAT'].astype('int64')\n",
    "imptest_ch['AGE_CAT'] = imptest_ch['AGE_CAT'].astype('int64')\n",
    "imptrain_noch['AGE_CAT'] = imptrain_noch['AGE_CAT'].astype('int64')\n",
    "imptest_noch['AGE_CAT'] = imptest_noch['AGE_CAT'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final train and test set for child and no child \n",
    "save_csv(imptrain_ch, 'ftrain_ch.csv')\n",
    "save_csv(imptest_ch, 'ftest_ch.csv')\n",
    "save_csv(imptrain_noch, 'ftrain_noch.csv')\n",
    "save_csv(imptest_noch, 'ftest_noch.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('full_data.csv')\n",
    "info_dict = {'Column':df.columns, 'Count':df.count(), 'Type':df.dtypes}\n",
    "dfinfo = pd.DataFrame(info_dict).reset_index(drop=True)\n",
    "save_csv(dfinfo, 'dfinfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General data description plot\n",
    "df = open_csv('full_data.csv')\n",
    "info_dict = {'Column':df.columns, 'Count':df.count(), 'Type':df.dtypes}\n",
    "dfinfo = pd.DataFrame(info_dict).reset_index(drop=True)\n",
    "dfdes = sns.catplot(x='Count', y='Column', hue='Type', data=dfinfo, kind='bar')\n",
    "dfdes.set(xlabel='Number of Records', ylabel='Variable')\n",
    "dfdes.fig.set_size_inches(10,10)\n",
    "dfdes.fig.suptitle('WGM 2018 Data Overview', y=1.0, fontsize=14)\n",
    "dfdes.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/dfdes.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = {1:'United States', 2:'Egypt', 3:'Morocco', 4:'Lebanon', 5:'Saudi Arabia', 6:'Jordan', 8:'Turkey', 9:'Pakistan', 10:'Indonesia', 11:'Bangladesh', 12:'United Kingdom', 13:'France', 14:'Germany', 15:'Netherlands', 16:'Belgium', 17:'Spain', 18:'Italy', 19:'Poland', 20:'Hungary', 21:'Czech Republic', 22:'Romania', 23:'Sweden', 24:'Greece', 25:'Denmark', 26:'Iran', 28:'Singapore', 29:'Japan', 30:'China', 31:'India', 32:'Venezuela', 33:'Brazil', 34:'Mexico', 35:'Nigeria', 36:'Kenya', 37:'Tanzania', 38:'Israel', 39:'Palestinian Territories', 40:'Ghana', 41:'Uganda', 42:'Benin', 43:'Madagascar', 44:'Malawi', 45:'South Africa', 46:'Canada', 47:'Australia', 48:'Philippines', 49:'Sri Lanka', 50:'Vietnam', 51:'Thailand', 52:'Cambodia', 53:'Laos', 54:'Myanmar', 55:'New Zealand', 57:'Botswana', 60:'Ethiopia', 61:'Mali', 62:'Mauritania', 63:'Mozambique', 64:'Niger', 65:'Rwanda', 66:'Senegal', 67:'Zambia', 68:'South Korea', 69:'Taiwan', 70:'Afghanistan', 71:'Belarus', 72:'Georgia', 73:'Kazakhstan', 74:'Kyrgyzstan', 75:'Moldova', 76:'Russia', 77:'Ukraine', 78:'Burkina Faso', 79:'Cameroon', 80:'Sierra Leone', 81:'Zimbabwe', 82:'Costa Rica', 83:'Albania', 84:'Algeria', 87:'Argentina', 88:'Armenia', 89:'Austria', 90:'Azerbaijan', 96:'Bolivia', 97:'Bosnia and Herzegovina', 99:'Bulgaria', 100:'Burundi', 103:'Chad', 104:'Chile', 105:'Colombia', 106:'Comoros', 108:'Republic of Congo', 109:'Croatia', 111:'Cyprus', 114:'Dominican Republic', 115:'Ecuador', 116:'El Salvador', 119:'Estonia', 121:'Finland', 122:'Gabon', 124:'Guatemala', 125:'Guinea', 128:'Haiti', 129:'Honduras', 130:'Iceland',131:'Iraq', 132:'Ireland', 134:'Ivory Coast', 137:'Kuwait', 138:'Latvia', 140:'Liberia', 141:'Libya', 143:'Lithuania', 144:'Luxembourg', 145:'Macedonia', 146:'Malaysia', 148:'Malta', 150:'Mauritius', 153:'Mongolia', 154:'Montenegro', 155:'Namibia', 157:'Nepal', 158:'Nicaragua', 160:'Norway', 163:'Panama', 164:'Paraguay', 165:'Peru', 166:'Portugal', 173:'Serbia', 175:'Slovakia', 176:'Slovenia', 183:'Eswatini', 184:'Switzerland', 185:'Tajikistan', 186:'The Gambia', 187:'Togo', 190:'Tunisia', 191:'Turkmenistan', 193:'United Arab Emirates', 194:'Uruguay', 195:'Uzbekistan', 197:'Yemen', 198:'Kosovo', 202:'Northern Cyprus'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of records across every country\n",
    "df = open_csv('full_data.csv')\n",
    "df.insert(loc=1, column='CTRY_NAME', value=df['CTRY'].replace(country))\n",
    "ctrycount = pd.DataFrame(data=zip(df['CTRY'].value_counts().index, df['CTRY_NAME'].value_counts().index, df['CTRY_NAME'].value_counts().values), columns=['Country Code', 'Country', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ctryplot = sns.scatterplot(data=ctrycount, x=\"Country Code\", y=\"Count\", ax=ax, color='#EEB03F')\n",
    "for line in range(0,ctrycount.shape[0]):\n",
    "    if (ctrycount.loc[line, 'Country'] == 'Iceland') and ctrycount.loc[line, 'Count'] == 500:\n",
    "        ctryplot.text(ctrycount['Country Code'][line]-11.5, ctrycount['Count'][line], ctrycount['Country'][line], horizontalalignment='left', size='medium', color='black', weight='regular')\n",
    "    elif (ctrycount.loc[line, 'Country'] == 'Haiti') and ctrycount.loc[line, 'Count'] == 500:\n",
    "        ctryplot.text(ctrycount['Country Code'][line]+1.5, ctrycount['Count'][line], ctrycount['Country'][line], horizontalalignment='left', size='medium', color='black', weight='regular')\n",
    "    elif ctrycount.loc[line, 'Count'] > 1000:\n",
    "        ctryplot.text(ctrycount['Country Code'][line]+0.5, ctrycount['Count'][line], ctrycount['Country'][line], horizontalalignment='left', size='medium', color='black', weight='regular')\n",
    "    else:\n",
    "        continue\n",
    "ctryplot.set(xlabel='Country', ylabel='Number of Sample Data')\n",
    "fig = ctryplot.get_figure()\n",
    "fig.suptitle('Number of sample data across countries', y=0.94, fontsize=14)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/ctrycount.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Distribution WGM 2018 (long)\n",
    "fig = plt.figure(figsize=(20,30))\n",
    "gs = GridSpec(11,5, wspace=0.2, hspace=0.5, figure=fig)\n",
    "count = 0\n",
    "while count <= 55:\n",
    "    if count < 6:\n",
    "        for c, d in zip(range(5), range(5,10)):\n",
    "            ax = fig.add_subplot(gs[0,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 5 < count < 11:\n",
    "        for c, d in zip(range(5), range(10,15)):\n",
    "            ax = fig.add_subplot(gs[1,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 10 < count < 16:\n",
    "        for c, d in zip(range(5), range(15,20)):\n",
    "            ax = fig.add_subplot(gs[2,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 15 < count < 21:\n",
    "        for c, d in zip(range(5), range(20,25)):\n",
    "            ax = fig.add_subplot(gs[3,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 20 < count < 26:\n",
    "        for c, d in zip(range(5), range(25,30)):\n",
    "            ax = fig.add_subplot(gs[4,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 25 < count < 31:\n",
    "        for c, d in zip(range(5), range(30,35)):\n",
    "            ax = fig.add_subplot(gs[5,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 30 < count < 36:\n",
    "        for c, d in zip(range(5), range(35,40)):\n",
    "            ax = fig.add_subplot(gs[6,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "\n",
    "    elif 35 < count < 41:\n",
    "        for c, d in zip(range(5), range(40,45)):\n",
    "            ax = fig.add_subplot(gs[7,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    \n",
    "    elif 40 < count < 46:\n",
    "        for c, d in zip(range(5), range(45,50)):\n",
    "            ax = fig.add_subplot(gs[8,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "\n",
    "    elif 45 < count < 51:\n",
    "        for c, d in zip(range(5), range(50,55)):\n",
    "            ax = fig.add_subplot(gs[9,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "\n",
    "    else:\n",
    "        for c, d in zip(range(5), range(55,60)):\n",
    "            ax = fig.add_subplot(gs[10,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "\n",
    "fig.suptitle(\"WGM 2018 Data Distribution\", fontsize=16, y=0.9)\n",
    "fig.tight_layout()\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/datadist.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Distribution WGM 2018 (wide)\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "gs = GridSpec(5,11, wspace=0.2, hspace=0.5, figure=fig)\n",
    "count = 0\n",
    "while count <= 55:\n",
    "    if count < 12:\n",
    "        for c, d in zip(range(12), range(5,16)):\n",
    "            ax = fig.add_subplot(gs[0,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 11 < count < 23:\n",
    "        for c, d in zip(range(12), range(16,27)):\n",
    "            ax = fig.add_subplot(gs[1,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 22 < count < 34:\n",
    "        for c, d in zip(range(12), range(27,38)):\n",
    "            ax = fig.add_subplot(gs[2,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 33 < count < 45:\n",
    "        for c, d in zip(range(12), range(38,49)):\n",
    "            ax = fig.add_subplot(gs[3,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    elif 44 < count < 56:\n",
    "        for c, d in zip(range(12), range(49,60)):\n",
    "            ax = fig.add_subplot(gs[4,c])\n",
    "            sns.violinplot(x=df.iloc[:,[d]], ax=ax)\n",
    "            ax.set_title(df.iloc[:,[d]].columns.values[0])\n",
    "            count += 1\n",
    "    \n",
    "fig.suptitle(\"WGM 2018 Data Distribution\", fontsize=18, y=0.95)\n",
    "fig.tight_layout()\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/datadist-2.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('full_data.csv')\n",
    "missingdf = missing_val(df)\n",
    "save_csv(missingdf, \"missing_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values \n",
    "df = open_csv('full_data.csv')\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "msplot = sns.heatmap(df.isnull(), cbar=False, ax=ax)\n",
    "fig = msplot.get_figure()\n",
    "fig.suptitle('Missing data in original WGM 2018 data set', y=0.94, fontsize=30)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/msplot.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[52, 30, 2, 137, 53, 5, 185, 191, 193, 50]\n['Cambodia', 'China', 'Egypt', 'Kuwait', 'Laos', 'Saudi Arabia', 'Tajikistan', 'Turkmenistan', 'United Arab Emirates', 'Vietnam']\n"
    }
   ],
   "source": [
    "# Check abnormal missing data for TRU_NATGOV\n",
    "normal, mapnormal, notnormal, mapabnormal = check_ctry_unique(check_ctry('TRU_NATGOV'), 'TRU_NATGOV')\n",
    "print(notnormal)\n",
    "print(mapabnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows these countries have entire missing value for TRU_NATGOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Country  Country Code\n0  Saudi Arabia             5\n[5]\n['Saudi Arabia']\n"
    }
   ],
   "source": [
    "normal, mapnormal, notnormal, mapabnormal = check_ctry_unique(check_ctry('TRU_GOVADV'), 'TRU_GOVADV')\n",
    "print(check_ctry('TRU_GOVADV'))\n",
    "print(notnormal)\n",
    "print(mapabnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[30]\n['China']\n"
    }
   ],
   "source": [
    "# Check abnormal missing data for RELIG\n",
    "normal, mapnormal, notnormal, mapabnormal = check_ctry_unique(check_ctry('RELIG'), 'RELIG')\n",
    "print(notnormal)\n",
    "print(mapabnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows that only China have entire missing value in RELIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[30, 137, 5]\n['China', 'Kuwait', 'Saudi Arabia']\n"
    }
   ],
   "source": [
    "normal, mapnormal, notnormal, mapabnormal = check_ctry_unique(check_ctry('SC_DISRELIG'), 'SC_DISRELIG')\n",
    "print(notnormal)\n",
    "print(mapabnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[30, 137, 5]\n['China', 'Kuwait', 'Saudi Arabia']\n"
    }
   ],
   "source": [
    "normal, mapnormal, notnormal, mapabnormal = check_ctry_unique(check_ctry('BLV_SCRELIG'), 'BLV_SCRELIG')\n",
    "print(notnormal)\n",
    "print(mapabnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[62, 64, 32]\n['Mauritania', 'Niger', 'Venezuela']\n"
    }
   ],
   "source": [
    "normal, mapnormal, notnormal, mapabnormal = check_ctry_unique(check_ctry('HHI'), 'HHI')\n",
    "print(notnormal)\n",
    "print(mapabnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[202]\n['Northern Cyprus']\n"
    }
   ],
   "source": [
    "normal, mapnormal, notnormal, mapabnormal = check_ctry_unique(check_ctry('CTRY_INC'), 'CTRY_INC')\n",
    "print(notnormal)\n",
    "print(mapabnormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate response for these variables (plot in Tableau)\n",
    "grp1 = ['SC_KNOWL', 'UND_SCSCI', 'SC_DZ', 'SC_POET', 'SC_PS', 'SC_SS', 'SC_UNI', 'SCINFO_30D', 'MDHINFO_30D', 'SC_INT', 'MDH_INT', 'SCI_BENPPL', 'SCI_BENRESP', 'SCTECH_IMPRLIFE', 'SCTECH_JOBS']\n",
    "grp2 = ['TRU_NEIGHB', 'TRU_NATGOV', 'TRU_SCI', 'TRU_JO', 'TRU_HCW', 'TRU_NGOPPL', 'TRU_TH', 'TRU_SC', 'TRUSCI_ACCINFO', 'TRUSCIUNI_BEN', 'TRUSCIUNI_HON', 'TRUSCICOM_BEN', 'TRUSCICOM_HON', 'TRU_PPLADV', 'TRU_GOVADV', 'TRU_HCWADV', 'CONF_NGO', 'CONF_HOSP']\n",
    "grp3 = ['HRD_VAC', 'VAC_IMPTCH', 'VAC_SF', 'VAC_EFF', 'ANY_CH', 'CH_RVAC']\n",
    "grp4 = ['RELIG', 'SC_DISRELIG', 'BLV_SCRELIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescount(list):\n",
    "    df = open_csv('full_data.csv')\n",
    "    grpdf = pd.DataFrame()\n",
    "    for col in list:\n",
    "        val = df[col].value_counts().sort_index(ascending=True).values\n",
    "        idx = df[col].value_counts().sort_index(ascending=True).index\n",
    "        var = [df[[col]].columns.values[0] for i in range(len(df[col].value_counts()))]\n",
    "        d = {'var':var, 'val':val, 'idx':idx}\n",
    "        grpdf = pd.concat([pd.DataFrame(d), grpdf])\n",
    "    return grpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp1df = rescount(grp1)\n",
    "grp2df = rescount(grp2)\n",
    "grp3df = rescount(grp3)\n",
    "grp4df = rescount(grp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(grp1df, 'grp1df.csv')\n",
    "save_csv(grp2df, 'grp2df.csv')\n",
    "save_csv(grp3df, 'grp3df.csv')\n",
    "save_csv(grp4df, 'grp4df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Vaccine Attitude (Child vs No Child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('fpp_df.csv')\n",
    "df_ch = open_csv('df_ch.csv')\n",
    "df_noch = open_csv('df_noch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vac_res(df, name, word):\n",
    "    response = {0:1, 1:2, 2:3, 3:4, 4:5, 5:99}\n",
    "    ndf_1 = df['VAC_IMPTCH'].value_counts().sort_index(ascending=True).values\n",
    "    ndf_2 = df['VAC_SF'].value_counts().sort_index(ascending=True).values\n",
    "    ndf_3 = df['VAC_EFF'].value_counts().sort_index(ascending=True).values\n",
    "    fdf = pd.DataFrame(data=zip(ndf_1, ndf_2, ndf_3), columns=['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF'])\n",
    "    fdf = fdf.reset_index().rename(columns={'index':'Responses'})\n",
    "    fdf['Responses'] = fdf.replace(response).astype('str')\n",
    "    fdf['Child'] = [word for i in range(len(fdf))]\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacres_ch = check_vac_res(df_ch, 'df_ch', 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacres_noch = check_vac_res(df_noch, 'df_noch', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacres = pd.concat([vacres_ch, vacres_noch])\n",
    "vacres = vacres.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(vacres, 'vacres.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Countries Vaccine Attitude Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_vac99(df):\n",
    "    vdf = df[(df['VAC_IMPTCH'] != 99) & (df['VAC_SF'] != 99) & (df['VAC_EFF'] != 99)]\n",
    "    return vdf\n",
    "\n",
    "def decode_vac(df):\n",
    "    vac_code = {1:5, 2:4, 3:3, 4:2, 5:1}\n",
    "    df['VAC_IMPTCH'] = df['VAC_IMPTCH'].replace(vac_code)\n",
    "    df['VAC_SF'] = df['VAC_SF'].replace(vac_code)\n",
    "    df['VAC_EFF'] = df['VAC_EFF'].replace(vac_code)\n",
    "    return df\n",
    "\n",
    "def create_index(df):\n",
    "    idx = df[['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF']].mean(axis=1)\n",
    "    df.insert(loc=36, column='VAC_IDX', value=idx)\n",
    "    return df\n",
    "\n",
    "def assign_vacidx_cat(df):\n",
    "    idx_cat = []\n",
    "    for idx in df['VAC_IDX']:\n",
    "        if idx < 1.7:\n",
    "            idx = 'Low'\n",
    "            idx_cat.append(idx)\n",
    "        elif 1.7 < idx < 3.4:\n",
    "            idx = 'Medium'\n",
    "            idx_cat.append(idx)\n",
    "        else:\n",
    "            idx = 'High'\n",
    "            idx_cat.append(idx)\n",
    "    df.insert(loc=37, column='VAC_LVL', value=idx_cat)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('fpp_df.csv')\n",
    "ftrain_ch = open_csv('ftrain_ch.csv')\n",
    "ftest_ch = open_csv('ftest_ch.csv')\n",
    "ftrain_noch = open_csv('ftrain_noch.csv')\n",
    "ftest_noch = open_csv('ftest_noch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop response = 99 in vaccine questions\n",
    "df_vacidx = drop_vac99(df)\n",
    "train_ch_vacidx = drop_vac99(ftrain_ch)\n",
    "test_ch_vacidx = drop_vac99(ftest_ch)\n",
    "train_noch_vacidx = drop_vac99(ftrain_noch)\n",
    "test_noch_vacidx =drop_vac99(ftest_noch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode vaccine questions: 1=5, 2=4, 3=3, 4=2, 5=1\n",
    "df_vacidx = decode_vac(df_vacidx)\n",
    "train_ch_vacidx = decode_vac(train_ch_vacidx)\n",
    "test_ch_vacidx = decode_vac(test_ch_vacidx)\n",
    "train_noch_vacidx = decode_vac(train_noch_vacidx)\n",
    "test_noch_vacidx =decode_vac(test_noch_vacidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vaccine Index\n",
    "df_vacidx = create_index(df_vacidx)\n",
    "train_ch_vacidx = create_index(train_ch_vacidx)\n",
    "test_ch_vacidx = create_index(test_ch_vacidx)\n",
    "train_noch_vacidx = create_index(train_noch_vacidx)\n",
    "test_noch_vacidx = create_index(test_noch_vacidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Vaccine Index into Low, Medium, High Category\n",
    "df_vacidx = assign_vacidx_cat(df_vacidx)\n",
    "train_ch_vacidx = assign_vacidx_cat(train_ch_vacidx)\n",
    "test_ch_vacidx = assign_vacidx_cat(test_ch_vacidx)\n",
    "train_noch_vacidx = assign_vacidx_cat(train_noch_vacidx)\n",
    "test_noch_vacidx = assign_vacidx_cat(test_noch_vacidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(df_vacidx, 'df_vacidx.csv')\n",
    "save_csv(train_ch_vacidx, 'train_ch_vacidx.csv')\n",
    "save_csv(test_ch_vacidx, 'test_ch_vacidx.csv')\n",
    "save_csv(train_noch_vacidx, 'train_noch_vacidx.csv')\n",
    "save_csv(test_noch_vacidx, 'test_noch_vacidx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctry = df_vacidx['CTRY'].replace(country)\n",
    "df_vacidx_ctry = df_vacidx.copy()\n",
    "df_vacidx_ctry.insert(loc=1, column='CTRY_NAME', value=ctry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(df_vacidx_ctry, 'df_vacidx_ctry.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Vaccine Attitude with Demographic and Country-level variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_99 = drop_vac99(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without NA\n",
    "def ridgedist(df):\n",
    "    age_cat = {1:'Adolescent', 2:'Adult', 3:'Elder', np.NaN:'NAN'}\n",
    "    gen = {1:'Male', 2:'Female'}\n",
    "    edu = {1:'Primary', 2:'Secondary', 3:'Tertiary', np.NaN:'NAN'}\n",
    "    liv_ar = {1:'Rural', 2:'Urban', np.NaN:'NAN'}\n",
    "    hhi = {1:'Lowest', 2:'Lower Middle', 3:'Middle', 4:'Upper Middle', 5:'Upper', np.NaN:'NAN'}\n",
    "    # rgn = {0:'N/A', 1:'Eastern Africa',2:'Central Africa',3:'North Africa',4:'Southern Africa',5:'Western Africa',6:'Central America and Mexico',7:'Northern America',8:'South America',9:'Central Asia',10:'East Asia',11:'Southeast Asia',12:'South Asia',13:'Middle East',14:'Eastern Europe',15:'Northern Europe',16:'Southern Europe',17:'Western Europe',18:'Aus/NZ'}\n",
    "    rgn = {0:'N/A', 1:'EAFR',2:'CAFR',3:'NAFR',4:'SAFR',5:'WAFR',6:'CAMX',7:'NAM',8:'SAM',9:'CCA',10:'EA',11:'SEA',12:'SA',13:'ME',14:'EE',15:'NE',16:'SE',17:'WE',18:'AUS/NZ'}\n",
    "    subj_hhi = {1:'Comfortable', 2:'Sustainable', 3:'Difficult', np.NaN:'NAN'}\n",
    "    ctry_inc = {1:'LI', 2:'LMI', 3:'UMI', 4:'HI', np.NaN:'NAN'}\n",
    "    emp_stat = {1:'F/T Employer', 2:'F/T Self', 3:'P/T - F/T', 4:'UE', 5:'P/T + F/T', 6:'OW', np.NaN:'NAN'}\n",
    "    df_99 = drop_vac99(df)\n",
    "    df_99['AGE_CAT'] = df_99['AGE_CAT'].replace(age_cat)\n",
    "    df_99['GEN'] = df_99['GEN'].replace(gen)\n",
    "    df_99['EDU'] = df_99['EDU'].replace(edu)\n",
    "    df_99['LIV_AR'] = df_99['LIV_AR'].replace(liv_ar)\n",
    "    df_99['HHI'] = df_99['HHI'].replace(hhi)\n",
    "    df_99['RGN'] = df_99['RGN'].replace(rgn)\n",
    "    df_99['SUBJ_HHI'] = df_99['SUBJ_HHI'].replace(subj_hhi)\n",
    "    df_99['CTRY_INC'] = df_99['CTRY_INC'].replace(ctry_inc)\n",
    "    df_99['EMP_STAT'] = df_99['EMP_STAT'].replace(emp_stat)\n",
    "    return df_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgedist_df = ridgedist(df)\n",
    "save_csv(ridgedist_df, 'ridgedist_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With NA\n",
    "def ridgedist_na_ch(df):\n",
    "    age_cat = {1:'Adolescent', 2:'Adult', 3:'Elder'}\n",
    "    gen = {1:'Male', 2:'Female'}\n",
    "    edu = {1:'Primary', 2:'Secondary', 3:'Tertiary'}\n",
    "    liv_ar = {1:'Rural', 2:'Urban'}\n",
    "    hhi = {1:'Lowest', 2:'Lower Middle', 3:'Middle', 4:'Upper Middle', 5:'Upper'}\n",
    "    # rgn = {0:'N/A', 1:'Eastern Africa',2:'Central Africa',3:'North Africa',4:'Southern Africa',5:'Western Africa',6:'Central America and Mexico',7:'Northern America',8:'South America',9:'Central Asia',10:'East Asia',11:'Southeast Asia',12:'South Asia',13:'Middle East',14:'Eastern Europe',15:'Northern Europe',16:'Southern Europe',17:'Western Europe',18:'Aus/NZ'}\n",
    "    rgn = {0:'N/A', 1:'EAFR',2:'CAFR',3:'NAFR',4:'SAFR',5:'WAFR',6:'CAMX',7:'NAM',8:'SAM',9:'CCA',10:'EA',11:'SEA',12:'SA',13:'ME',14:'EE',15:'NE',16:'SE',17:'WE',18:'AUS/NZ'}\n",
    "    subj_hhi = {1:'Comfortable', 2:'Sustainable', 3:'Difficult'}\n",
    "    ctry_inc = {1:'LI', 2:'LMI', 3:'UMI', 4:'HI'}\n",
    "    emp_stat = {1:'F/T Employer', 2:'F/T Self', 3:'P/T - F/T', 4:'UE', 5:'P/T + F/T', 6:'OW'}\n",
    "    any_ch = {1:'HV_CH', 2:'NO_CH', 3:'HV_CH_NOLIV', 4:'DK', 5:'REF'}\n",
    "    ch_rvac = {1:'Yes', 2:'No', 98:'DK', 99:'RF'}\n",
    "    df_99 = drop_vac99(df)\n",
    "    df_99['AGE_CAT'] = df_99['AGE_CAT'].replace(age_cat)\n",
    "    df_99['GEN'] = df_99['GEN'].replace(gen)\n",
    "    df_99['EDU'] = df_99['EDU'].replace(edu)\n",
    "    df_99['LIV_AR'] = df_99['LIV_AR'].replace(liv_ar)\n",
    "    df_99['HHI'] = df_99['HHI'].replace(hhi)\n",
    "    df_99['RGN'] = df_99['RGN'].replace(rgn)\n",
    "    df_99['SUBJ_HHI'] = df_99['SUBJ_HHI'].replace(subj_hhi)\n",
    "    df_99['CTRY_INC'] = df_99['CTRY_INC'].replace(ctry_inc)\n",
    "    df_99['EMP_STAT'] = df_99['EMP_STAT'].replace(emp_stat)\n",
    "    df_99['ANY_CH'] = df_99['ANY_CH'].replace(any_ch)\n",
    "    df_99['CH_RVAC'] = df_99['CH_RVAC'].replace(ch_rvac)\n",
    "    return df_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgedist_na_ch_df = ridgedist_na_ch(df)\n",
    "save_csv(ridgedist_na_ch_df, 'ridgedist_na_ch_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without drop_99\n",
    "def vac_overview(df_99):\n",
    "    age_cat = {1:'Adolescent', 2:'Adult', 3:'Elder'}\n",
    "    gen = {1:'Male', 2:'Female'}\n",
    "    edu = {1:'Primary', 2:'Secondary', 3:'Tertiary'}\n",
    "    liv_ar = {1:'Rural', 2:'Urban'}\n",
    "    hhi = {1:'Lowest', 2:'Lower Middle', 3:'Middle', 4:'Upper Middle', 5:'Upper'}\n",
    "    rgn = {0:'N/A', 1:'Eastern Africa',2:'Central Africa',3:'North Africa',4:'Southern Africa',5:'Western Africa',6:'Central America & Mexico',7:'Northern America',8:'South America',9:'Central Asia',10:'East Asia',11:'Southeast Asia',12:'South Asia',13:'Middle East',14:'Eastern Europe',15:'Northern Europe',16:'Southern Europe',17:'Western Europe',18:'Australia & NZ'}\n",
    "    subj_hhi = {1:'Comfortable', 2:'Sustainable', 3:'Difficult'}\n",
    "    ctry_inc = {1:'LI', 2:'LMI', 3:'UMI', 4:'HI'}\n",
    "    # emp_stat = {1:'F/T Employer', 2:'F/T Self', 3:'P/T - F/T', 4:'UE', 5:'P/T + F/T', 6:'OW'}\n",
    "    emp_stat = {1:'Employed full time for an employer', 2:'Employed full time for self', 3:'Employed part time but do not want full time', 4:'Unemployed', 5:'Employed part time but want full time', 6:'Out of workforce'}\n",
    "    any_ch = {1:'HV_CH', 2:'NO_CH', 3:'HV_CH_NOLIV', 4:'DK', 5:'REF'}\n",
    "    ch_rvac = {1:'Yes', 2:'No', 98:'DK', 99:'RF'}\n",
    "    df_99['AGE_CAT'] = df_99['AGE_CAT'].replace(age_cat)\n",
    "    df_99['GEN'] = df_99['GEN'].replace(gen)\n",
    "    df_99['EDU'] = df_99['EDU'].replace(edu)\n",
    "    df_99['LIV_AR'] = df_99['LIV_AR'].replace(liv_ar)\n",
    "    df_99['HHI'] = df_99['HHI'].replace(hhi)\n",
    "    df_99['RGN'] = df_99['RGN'].replace(rgn)\n",
    "    df_99['SUBJ_HHI'] = df_99['SUBJ_HHI'].replace(subj_hhi)\n",
    "    df_99['CTRY_INC'] = df_99['CTRY_INC'].replace(ctry_inc)\n",
    "    df_99['EMP_STAT'] = df_99['EMP_STAT'].replace(emp_stat)\n",
    "    df_99['ANY_CH'] = df_99['ANY_CH'].replace(any_ch)\n",
    "    df_99['CH_RVAC'] = df_99['CH_RVAC'].replace(ch_rvac)\n",
    "    return df_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('full_data.csv')\n",
    "vac_overview = vac_overview(df)\n",
    "save_csv(vac_overview, 'vac_overview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include decoded ANY_CH and CH_RVAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "any_ch = {1:'HV_CH', 2:'NO_CH', 3:'HV_CH_NOLIV', 4:'DK', 5:'REF', np.NaN:'NAN'}\n",
    "ch_rvac = {1:'Yes', 2:'No', 98:'DK', 99:'RF', np.NaN:'NAN'}\n",
    "ridgedist_df = open_csv('ridgedist_df.csv')\n",
    "ridgedistvac_df = ridgedist_df.copy()\n",
    "ridgedistvac_df['ANY_CH'] = ridgedistch_df['ANY_CH'].replace(any_ch)\n",
    "ridgedistvac_df['CH_RVAC'] = ridgedistch_df['CH_RVAC'].replace(ch_rvac)\n",
    "save_csv(ridgedistvac_df, 'ridgedistvac_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between TRUSCI_IDX and Vaccine Attitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "recode = {1:'Strongly agree', 2:'Somewhat agree', 3:'Neither agree nor disagree', 4:'Somewhat disagree', 5:'Strongly disagree', 99:\"DK/Refused\"}\n",
    "trusci_df = df.copy()\n",
    "trusci_df['VAC_IMPTCH'] = trusci_df['VAC_IMPTCH'].replace(recode)\n",
    "trusci_df['VAC_SF'] = trusci_df['VAC_SF'].replace(recode)\n",
    "trusci_df['VAC_EFF'] = trusci_df['VAC_EFF'].replace(recode)\n",
    "fig, ax = plt.subplots(1,3, figsize=(40,14))\n",
    "ax1 = sns.boxplot(x='VAC_IMPTCH', y='TRUSCI_IDX', data=trusci_df, ax=ax[0], order=['Strongly agree', 'Somewhat agree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly disagree', 'DK/Refused'])\n",
    "ax2 = sns.boxplot(x='VAC_SF', y='TRUSCI_IDX', data=trusci_df, ax=ax[1], order=['Strongly agree', 'Somewhat agree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly disagree', 'DK/Refused'])\n",
    "ax3 = sns.boxplot(x='VAC_EFF', y='TRUSCI_IDX', data=trusci_df, ax=ax[2], order=['Strongly agree', 'Somewhat agree', 'Neither agree nor disagree', 'Somewhat agree', 'Strongly disagree', 'DK/Refused'])\n",
    "plt.setp(ax1.get_xticklabels(), rotation=25)\n",
    "plt.setp(ax2.get_xticklabels(), rotation=25)\n",
    "plt.setp(ax3.get_xticklabels(), rotation=25)\n",
    "ax1.set_title(\"Vaccine is important to children\", fontsize=16)\n",
    "ax2.set_title(\"Vaccine is safe\", fontsize=16)\n",
    "ax3.set_title(\"Vaccine is effective\", fontsize=16)\n",
    "plt.suptitle(\"Relationships between Trust Scientist Index and Vaccine Attitudes\", fontsize=20)\n",
    "fig.savefig(\"/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/trusc_idx_vac.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check country percentage of never heard of vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv(\"vac_overview.csv\")\n",
    "d = {}\n",
    "for i, k in country.items():\n",
    "    try:\n",
    "        d[i] = [len(df[df['CTRY']==i]),df[df['CTRY']==i]['HRD_VAC'].value_counts()[2]]\n",
    "    except:\n",
    "        pass\n",
    "ctry_hrdvac = pd.DataFrame(d).transpose().reset_index()\n",
    "ctry_hrdvac = ctry_hrdvac.rename(columns={'index':'Country', 0:'Total', 1:'Never Heard Vaccine'})\n",
    "ctry_hrdvac['Country'] = ctry_hrdvac['Country'].replace(country)\n",
    "save_csv(ctry_hrdvac, 'ctry_hrdvac.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check difference in attitude within each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgn = {0:'N/A', 1:'Eastern Africa',2:'Central Africa',3:'North Africa',4:'Southern Africa',5:'Western Africa',6:'Central America and Mexico',7:'Northern America',8:'South America',9:'Central Asia',10:'East Asia',11:'Southeast Asia',12:'South Asia',13:'Middle East',14:'Eastern Europe',15:'Northern Europe',16:'Southern Europe',17:'Western Europe',18:'Aus/NZ'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv(\"vac_overview.csv\")\n",
    "d = {}\n",
    "for i, k in rgn.items():\n",
    "    try:\n",
    "        d[k] = [df[df['RGN']== k]['VAC_IMPTCH'].count(),df[df['RGN']==k]['VAC_IMPTCH'].value_counts().sort_index(ascending=True)[[1,2]].sum(), df[df['RGN']==k]['VAC_SF'].value_counts().sort_index(ascending=True)[[1,2]].sum(), df[df['RGN']==k]['VAC_EFF'].value_counts().sort_index(ascending=True)[[1,2]].sum()]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "rgn_vac = pd.DataFrame(d).transpose().reset_index()\n",
    "rgn_vac = rgn_vac.rename(columns={'index':'Country', 0:'Total', 1:'VAC_IMPTCH', 2:'VAC_SF', 3:'VAC_EFF'})\n",
    "save_csv(rgn_vac, 'rgn_vac.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check discrepency of response (strongly agree/somewhat agree) %\n",
    "rgn_vac['VAC_IMPTCH_SF'] = (((rgn_vac['VAC_IMPTCH']/rgn_vac['Total']) - (rgn_vac['VAC_SF']/rgn_vac['Total']))*100).round(0).astype('int64')\n",
    "rgn_vac['VAC_IMPTCH_EFF'] = (((rgn_vac['VAC_IMPTCH']/rgn_vac['Total']) - (rgn_vac['VAC_EFF']/rgn_vac['Total']))*100).round(0).astype('int64')\n",
    "rgn_vac['VAC_SF_EFF'] = (((rgn_vac['VAC_SF']/rgn_vac['Total']) - (rgn_vac['VAC_EFF']/rgn_vac['Total']))*100).round(0).astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check attitudes (disagree) for every country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('full_data.csv')\n",
    "d = {}\n",
    "for i, k in country.items():\n",
    "    try:\n",
    "        d[i] = [df[df['CTRY']== i]['VAC_IMPTCH'].count(), df[df['CTRY']==i]['VAC_IMPTCH'].value_counts().sort_index(ascending=True)[[4,5]].sum(), df[df['CTRY']==i]['VAC_SF'].value_counts().sort_index(ascending=True)[[4,5]].sum(), df[df['CTRY']==i]['VAC_EFF'].value_counts().sort_index(ascending=True)[[4,5]].sum()]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "ctry_disagree_vac = pd.DataFrame(d).transpose().reset_index()\n",
    "ctry_disagree_vac = ctry_disagree_vac.rename(columns={'index':'Country', 0:'Total', 1:'VAC_IMPTCH', 2:'VAC_SF', 3:'VAC_EFF'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctry_disagree_vac.insert(loc=1, column='Country Name', value=ctry_disagree_vac['Country'].replace(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_csv(ctry_disagree_vac, 'ctry_disagree_vac.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Age Distribution for Vaccine Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vac_age = open_csv(\"vac_overview.csv\")\n",
    "vac = {1:\"Strongly agree\", 2:'Somewhat agree', 3:'Neutral', 4:'Somewhat disagree', 5:'Strongly disagree', 99:'No Opinion'}\n",
    "vac_age['VAC_IMPTCH'] = vac_age['VAC_IMPTCH'].replace(vac)\n",
    "vac_age['VAC_SF'] = vac_age['VAC_SF'].replace(vac)\n",
    "vac_age['VAC_EFF'] = vac_age['VAC_EFF'].replace(vac)\n",
    "save_csv(vac_age, 'vac_age.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(30,8))\n",
    "sns.violinplot(x='VAC_IMPTCH', y='AGE', data=vac_age, ax=ax[0], order=['Strongly agree', 'Somewhat agree', 'Neutral', 'Somewhat disagree', 'Strongly disagree', 'No Opinion'])\n",
    "ax[0].set_title('Vaccine is important to children')\n",
    "sns.violinplot(x='VAC_SF', y='AGE', data=vac_age, ax=ax[1], order=['Strongly agree', 'Somewhat agree', 'Neutral', 'Somewhat disagree', 'Strongly disagree', 'No Opinion'])\n",
    "ax[1].set_title('Vaccine is safe')\n",
    "sns.violinplot(x='VAC_EFF', y='AGE', data=vac_age, ax=ax[2], order=['Strongly agree', 'Somewhat agree', 'Neutral', 'Somewhat disagree', 'Strongly disagree', 'No Opinion'])\n",
    "ax[2].set_title('Vaccine is effective')\n",
    "plt.setp(ax[0].get_xticklabels(), rotation=25)\n",
    "plt.setp(ax[1].get_xticklabels(), rotation=25)\n",
    "plt.setp(ax[2].get_xticklabels(), rotation=25)\n",
    "plt.suptitle(\"Distribution of Age for All Responses in Vaccine Questions\", fontsize=20)\n",
    "fig.savefig(\"/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/vac_age.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index development (Use full dataset)\n",
    "df = open_csv('full_data.csv')\n",
    "df = df.loc[:, ['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF']]\n",
    "df = df.dropna(subset=['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF'], how='all')\n",
    "df = df[(df['VAC_IMPTCH'] != 99) & (df['VAC_SF'] != 99) & (df['VAC_EFF'] != 99)]\n",
    "\n",
    "# Factor Analysis\n",
    "# Insert prepared dataframe (must not contain single unique value/Null in each column), number of factors, and loads\n",
    "loads, ev, v = factor_analysis(df, 1)\n",
    "factor_dataframe(df, loads)\n",
    "factor_plot(df, ev, 'vacidx.png')\n",
    "\n",
    "# Cronbach Alpha test\n",
    "factor1 = df[['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF']]\n",
    "factor1_alpha = pg.cronbach_alpha(factor1)\n",
    "print(factor1_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All loadings > 0.5, and Cronbach are 0.76 which is reliable to create index. Hence, take simple average of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrain_ch = open_csv('ftrain_ch.csv')\n",
    "ftest_ch = open_csv('ftest_ch.csv')\n",
    "ftrain_noch = open_csv('ftrain_noch.csv')\n",
    "ftest_noch = open_csv('ftest_noch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n            Factor 1\nVAR                 \nVAC_EFF     0.781782\nVAC_SF      0.765461\nVAC_IMPTCH  0.683318\n(0.7773013268916602, array([0.774, 0.78 ]))\n"
    }
   ],
   "source": [
    "idx_dev(ftrain_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n            Factor 1\nVAR                 \nVAC_EFF     0.775087\nVAC_SF      0.760399\nVAC_IMPTCH  0.667029\n(0.7667380783240179, array([0.761, 0.773]))\n"
    }
   ],
   "source": [
    "idx_dev(ftest_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n            Factor 1\nVAR                 \nVAC_SF      0.737136\nVAC_EFF     0.721709\nVAC_IMPTCH  0.664569\n(0.7419935174277057, array([0.736, 0.747]))\n"
    }
   ],
   "source": [
    "idx_dev(ftrain_noch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n            Factor 1\nVAR                 \nVAC_SF      0.754230\nVAC_EFF     0.735574\nVAC_IMPTCH  0.682700\n(0.7594353878939415, array([0.749, 0.77 ]))\n"
    }
   ],
   "source": [
    "idx_dev(ftest_noch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer\n",
    "import pingouin as pg\n",
    "\n",
    "def idx_dev(df):\n",
    "    df = df.loc[:, ['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF']]\n",
    "    df = df[(df['VAC_IMPTCH'] != 99) & (df['VAC_SF'] != 99) & (df['VAC_EFF'] != 99)]\n",
    "    # Factor Analysis\n",
    "    # Insert prepared dataframe (must not contain single unique value/null in each column) and number of factor(s)\n",
    "    loads, ev, v = factor_analysis(df, 1)\n",
    "    print(\"=== Loadings of Each Variable ===\")\n",
    "    factor_dataframe(df, loads.round(2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Cronbach Alpha test\n",
    "    factor = df[['VAC_IMPTCH', 'VAC_SF', 'VAC_EFF']]\n",
    "    factor_alpha = pg.cronbach_alpha(factor)\n",
    "    print(\"=== Cronbach Alpha ===\")\n",
    "    print(factor_alpha[0].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "=== Loadings of Each Variable ===\n\n\n            Factor 1\nVAR                 \nVAC_EFF         0.78\nVAC_SF          0.77\nVAC_IMPTCH      0.68\n\n\n=== Cronbach Alpha ===\n0.77\n"
    }
   ],
   "source": [
    "df = open_csv(\"full_data.csv\")\n",
    "idx_dev(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy df for testing MICE imputation in R\n",
    "from random import randint, choice\n",
    "d1 = []\n",
    "random.seed(42)\n",
    "for i in range(100):\n",
    "    d1.append(choice([randint(0,1), randint(97,99)]))\n",
    "d2 = []\n",
    "random.seed(60)\n",
    "for i in range(100):\n",
    "    d2.append(choice([randint(0,1), randint(97,99)]))\n",
    "d3 = []\n",
    "random.seed(100)\n",
    "for i in range(100):\n",
    "    d3.append(choice([randint(0,1), randint(97,99)]))\n",
    "edudf = pd.DataFrame(data=zip(d1,d2,d3), columns=['PS', 'SS', 'UNI'])\n",
    "edudf.loc[edudf['PS'] == 0, 'SS'] = np.NaN\n",
    "edudf.loc[edudf['SS'] == 0, 'UNI'] = np.NaN\n",
    "edudf = edudf.astype('Int64')\n",
    "edudf.to_csv('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/csv_data/edudf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ch = open_csv(\"test_ch.csv\")\n",
    "imptrain = open_csv(\"imptrain.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfa_test = test_ch\n",
    "mfa_test[['SC_SS', 'SC_UNI', 'VAC_IMPTCH', 'VAC_SF', 'VAC_EFF', 'CH_RVAC', 'AGE_CAT']] = mfa_test[['SC_SS', 'SC_UNI', 'VAC_IMPTCH', 'VAC_SF', 'VAC_EFF', 'CH_RVAC', 'AGE_CAT']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfa_test = mfa_test[['CTRY', 'HRD_VAC', 'VAC_IMPTCH', 'VAC_SF', 'VAC_EFF', 'ANY_CH', 'CH_RVAC', 'AGE', 'AGE_CAT', 'GEN']]\n",
    "country = ['CTRY']\n",
    "demographic = ['AGE', 'AGE_CAT', 'GEN']\n",
    "vaccine = ['HRD_VAC', 'VAC_IMPTCH', 'VAC_SF', 'VAC_EFF', 'ANY_CH', 'CH_RVAC']\n",
    "new_cols = country + demographic + vaccine\n",
    "mfa_test = mfa_test[new_cols]\n",
    "save_csv(mfa_test, 'mfa_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data\n",
    "ftrain_ch = open_csv('train_ch_vacidx.csv')\n",
    "ftest_ch = open_csv('test_ch_vacidx.csv')\n",
    "ftrain_noch = open_csv('train_noch_vacidx.csv')\n",
    "ftest_noch = open_csv('test_noch_vacidx.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For data with child\n",
    "def model_preprocess_clf_ch(df):\n",
    "    recode = {'High':3, 'Medium':2, 'Low':1}\n",
    "    df['VAC_LVL'] = df['VAC_LVL'].replace(recode)\n",
    "    df = df.drop(['CTRY', 'VAC_IDX', 'HRD_VAC', 'VAC_IMPTCH', 'VAC_SF', 'VAC_EFF', 'ANY_CH'], axis=1)\n",
    "    label = df[['VAC_LVL']]\n",
    "    feature = df.drop('VAC_LVL', axis=1)\n",
    "    return (feature, label)\n",
    "\n",
    "# For data without child\n",
    "def model_preprocess_clf_noch(df):\n",
    "    recode = {'High':3, 'Medium':2, 'Low':1}\n",
    "    df['VAC_LVL'] = df['VAC_LVL'].replace(recode)\n",
    "    df = df.drop([ 'CTRY', 'VAC_IDX', 'HRD_VAC', 'VAC_IMPTCH', 'VAC_SF', 'VAC_EFF'], axis=1)\n",
    "    label = df[['VAC_LVL']]\n",
    "    feature = df.drop('VAC_LVL', axis=1)\n",
    "    return (feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess for modelling (split feature and label)\n",
    "ch_train_feature, ch_train_label= model_preprocess_clf_ch(ftrain_ch)\n",
    "ch_test_feature, ch_test_label = model_preprocess_clf_ch(ftest_ch)\n",
    "noch_train_feature, noch_train_label = model_preprocess_clf_noch(ftrain_noch)\n",
    "noch_test_feature, noch_test_label = model_preprocess_clf_noch(ftest_noch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full dataset for child and no child (for CV)\n",
    "chdf_feature = pd.concat([ch_train_feature, ch_test_feature]).reset_index(drop=True)\n",
    "chdf_label = pd.concat([ch_train_label, ch_test_label]).reset_index(drop=True)\n",
    "nochdf_feature = pd.concat([noch_train_feature, noch_test_feature]).reset_index(drop=True)\n",
    "nochdf_label = pd.concat([noch_train_label, noch_test_label]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_cv(X_train, y_train, mod, mod_name):\n",
    "    cvs = cross_val_score(mod, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print(cvs)\n",
    "    print('\\n')\n",
    "    print(\"=== Mean Accuracy Score ===\")\n",
    "    print(\"Mean Accuracy Score - %s\"  %mod_name + \":\", cvs.mean().round(2))\n",
    "    return cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(mod, param, X_train, y_train):\n",
    "    gs = GridSearchCV(estimator=mod, param_grid=param, cv=5, scoring='accuracy')\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.88785249 0.88763557 0.8879248  0.88785249 0.8897968 ]\n\n\n=== Mean Accuracy Score ===\nMean Accuracy Score - Random Forest: 0.89\n"
    }
   ],
   "source": [
    "# Random Forest CV\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(ch_train_feature, ch_train_label)\n",
    "rfc_cvs_ori = tree_cv(ch_train_feature, ch_train_label, rfc, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'max_depth': 100, 'n_estimators': 130, 'oob_score': False}\n"
    }
   ],
   "source": [
    "# Perform Grid Search\n",
    "param = {'n_estimators':[110, 130, 150], 'max_depth':[20, 60, 100], 'oob_score':[True, False]}\n",
    "grid_search(rfc, param, ch_train_feature, ch_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.88821403 0.88806941 0.88864787 0.88785249 0.88943524]\n\n\n=== Mean Accuracy Score ===\nMean Accuracy Score - Random Forest: 0.89\n"
    }
   ],
   "source": [
    "# Random Forest CV using GS parameters\n",
    "rfc = RandomForestClassifier(n_estimators=130, max_depth=100, oob_score=False)\n",
    "rfc.fit(ch_train_feature, ch_train_label)\n",
    "rfc_cvs = tree_cv(ch_train_feature, ch_train_label, rfc, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_data = {'Model':['Ori RF', 'GSCV RF'], 'Accuracy':[rfc_cvs_ori.mean().round(5), rfc_cvs.mean().round(5)]}\n",
    "ht = pd.DataFrame(ht_data)\n",
    "ht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot before and after grid search\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.lineplot(x='Model', y='Accuracy', data=ht, sort=False, ax=ax)\n",
    "fig.suptitle('RF Accuracy Before and After Hyperparameter Tuning')\n",
    "fig.savefig(\"/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/htrf.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare RF, DF, and GB (Child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=34)\n",
    "dtc.fit(ch_train_feature, ch_train_label)\n",
    "pred = dtc.predict(ch_test_feature)\n",
    "dtc_acc = accuracy_score(ch_test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=12)\n",
    "rfc.fit(ch_train_feature, ch_train_label)\n",
    "pred = rfc.predict(ch_test_feature)\n",
    "rfc_acc = accuracy_score(ch_test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=10)\n",
    "gbc.fit(ch_train_feature, ch_train_label)\n",
    "pred = gbc.predict(ch_test_feature)\n",
    "gbc_acc = accuracy_score(ch_test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(mod, df):\n",
    "    # Plot feature importance\n",
    "    feature_importance = mod.feature_importances_ # unsorted array\n",
    "    idx = np.argsort(-feature_importance) # get sorted array indices in descending order (start with biggest value)\n",
    "\n",
    "    # Create dataframe with feature and score using the sorted indices\n",
    "    df_imp = pd.DataFrame(dict(Features=df.columns[idx],\n",
    "                            Scores=feature_importance[idx]))\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = sns.barplot(x='Scores', y='Features', data=df_imp, palette='summer')\n",
    "    ax.set_title('Variable Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_dfonly(mod, df):\n",
    "    # Plot feature importance\n",
    "    feature_importance = mod.feature_importances_ # unsorted array\n",
    "    idx = np.argsort(-feature_importance) # get sorted array indices in descending order (start with biggest value)\n",
    "\n",
    "    # Create dataframe with feature and score using the sorted indices\n",
    "    df_imp = pd.DataFrame(dict(Features=df.columns[idx],\n",
    "                            Scores=feature_importance[idx]))\n",
    "    return df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_df = feature_importance_dfonly(dtc, ch_train_feature)\n",
    "rfc_df = feature_importance_dfonly(rfc, ch_train_feature)\n",
    "gbc_df = feature_importance_dfonly(gbc, ch_train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance\n",
    "fig, ax = plt.subplots(1,3,figsize=(36,10))\n",
    "sns.barplot(x='Scores', y='Features', data=dtc_df, palette='Blues_r', ax=ax[0])\n",
    "ax[0].set_title('Decision Tree')\n",
    "sns.barplot(x='Scores', y='Features', data=rfc_df, palette='Blues_r', ax=ax[1])\n",
    "ax[1].set_title('Random Forest')\n",
    "sns.barplot(x='Scores', y='Features', data=gbc_df, palette='Blues_r', ax=ax[2])\n",
    "ax[2].set_title('Gradient Boosted Tree')\n",
    "fig.suptitle('Significant Predictors for Vaccine Attitude (with child)', fontsize=24)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/fimp_child_new.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for comparison\n",
    "comp_mod_ch = {'Model':['DT', 'RF', 'GB'], 'Accuracy':[dtc_acc.round(5), rfc_acc.round(5), gbc_acc.round(5)]}\n",
    "comp_mod_df_ch = pd.DataFrame(comp_mod_ch)\n",
    "save_csv(comp_mod_df_ch, 'ch_mod_comp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(x='Model', y='Accuracy', data=comp_mod_df_ch, sort=False, ax=ax)\n",
    "fig.suptitle('Comparison of DT, RF, and GB accuracy (with child)')\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/comp_child.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one feature importance only\n",
    "fig, ax = plt.subplots(figsize=(14,14))\n",
    "sns.barplot(x='Scores', y='Features', data=gbc_df, palette='Blues_r')\n",
    "fig.suptitle('Significant Predictors from Gradient Boosting (With Child)', fontsize=26)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/fimp_ch_gbc.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare DT, RF, and GB (without child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_noch = DecisionTreeClassifier(random_state=10)\n",
    "dtc_noch.fit(noch_train_feature, noch_train_label)\n",
    "pred = dtc_noch.predict(noch_test_feature)\n",
    "noch_dtc_acc = accuracy_score(noch_test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_noch = RandomForestClassifier(random_state=10)\n",
    "rfc_noch.fit(noch_train_feature, noch_train_label)\n",
    "pred = rfc_noch.predict(noch_test_feature)\n",
    "noch_rfc_acc = accuracy_score(noch_test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_noch = GradientBoostingClassifier(random_state=10)\n",
    "gbc_noch.fit(noch_train_feature, noch_train_label)\n",
    "pred = gbc_noch.predict(noch_test_feature)\n",
    "noch_gbc_acc = accuracy_score(noch_test_label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "noch_dtc_df = feature_importance_dfonly(dtc_noch, noch_train_feature)\n",
    "noch_rfc_df = feature_importance_dfonly(rfc_noch, noch_train_feature)\n",
    "noch_gbc_df = feature_importance_dfonly(gbc_noch, noch_train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Feature Importance\n",
    "fig, ax = plt.subplots(1,3,figsize=(36,10))\n",
    "sns.barplot(x='Scores', y='Features', data=noch_dtc_df, palette='Blues_r', ax=ax[0])\n",
    "ax[0].set_title('Decision Tree')\n",
    "sns.barplot(x='Scores', y='Features', data=noch_rfc_df, palette='Blues_r', ax=ax[1])\n",
    "ax[1].set_title('Random Forest')\n",
    "sns.barplot(x='Scores', y='Features', data=noch_gbc_df, palette='Blues_r', ax=ax[2])\n",
    "ax[2].set_title('Gradient Boosted Tree')\n",
    "fig.suptitle('Significant Predictors for Vaccine Attitude (without child)', fontsize=24)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/fimp_no_child_new.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for comparison\n",
    "comp_mod_noch = {'Model':['DT', 'RF', 'GB'], 'Accuracy':[noch_dtc_acc.round(5), noch_rfc_acc.round(5), noch_gbc_acc.round(5)]}\n",
    "comp_mod_df_noch = pd.DataFrame(comp_mod_noch)\n",
    "save_csv(comp_mod_df_noch, 'noch_mod_comp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(x='Model', y='Accuracy', data=comp_mod_df_noch, sort=False, ax=ax)\n",
    "fig.suptitle('Comparison of DT, RF, and GB accuracy (without child)')\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/comp_nochild.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one feature importance only\n",
    "fig, ax = plt.subplots(figsize=(14,14))\n",
    "sns.barplot(x='Scores', y='Features', data=noch_gbc_df, palette='Blues_r')\n",
    "fig.suptitle('Significant Predictors from Gradient Boosting (Without Child)', fontsize=26)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/fimp_noch_gbc.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine GBC\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
    "sns.barplot(x='Scores', y='Features', data=gbc_df, palette='Blues_r', ax=ax[0])\n",
    "ax[0].set_title('Significant Predictors from Gradient Boosting (With Child)', fontsize=14)\n",
    "sns.barplot(x='Scores', y='Features', data=noch_gbc_df, palette='Blues_r', ax=ax[1])\n",
    "ax[1].set_title('Significant Predictors from Gradient Boosting (Without Child)', fontsize=14)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/comb_fimpt.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,10))\n",
    "sns.lineplot(x='Model', y='Accuracy', data=comp_mod_df_ch, sort=False, ax=ax[0])\n",
    "ax[0].set_title('Comparison of DT, RF, and GB accuracy (with child)', fontsize=14)\n",
    "sns.lineplot(x='Model', y='Accuracy', data=comp_mod_df_noch, sort=False, ax=ax[1])\n",
    "ax[1].set_title('Comparison of DT, RF, and GB accuracy (without child)', fontsize=14)\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/mod_comp.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Model  Accuracy\n0    DT   0.81156\n1    RF   0.89133\n2    GB   0.89041",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DT</td>\n      <td>0.81156</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF</td>\n      <td>0.89133</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GB</td>\n      <td>0.89041</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "comp_mod_df_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  Model  Accuracy\n0    DT   0.74838\n1    RF   0.84619\n2    GB   0.84619",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DT</td>\n      <td>0.74838</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF</td>\n      <td>0.84619</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GB</td>\n      <td>0.84619</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "comp_mod_df_noch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.80744758 0.80383225 0.80759219 0.8054953  0.81083231]\n\n\n=== Mean Accuracy Score ===\nMean Accuracy Score - Decision Tree: 0.81\n"
    }
   ],
   "source": [
    "dtcv_ch = tree_cv(ch_train_feature, ch_train_label, dtc, 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.88778019 0.88843095 0.88886479 0.88850325 0.889146  ]\n\n\n=== Mean Accuracy Score ===\nMean Accuracy Score - Random Forest: 0.89\n"
    }
   ],
   "source": [
    "rfcv_ch = tree_cv(ch_train_feature, ch_train_label, rfc, 'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.88893709 0.88879248 0.88958785 0.88864787 0.89066455]\n\n\n=== Mean Accuracy Score ===\nMean Accuracy Score - Random Forest: 0.89\n"
    }
   ],
   "source": [
    "gbcv_ch = tree_cv(ch_train_feature, ch_train_label, gbc, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRUSCI_IDX Investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = open_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CTRY_NAME'] = df['CTRY'].replace(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RGN_NAME'] = df['RGN'].replace(rgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trusci_idx_ctry(df, ctry_1, ctry_2, ctry_3, ctry_4, ctry_5):\n",
    "    country = df[(df['CTRY_NAME'] == ctry_1) | (df['CTRY_NAME'] == ctry_2) | (df['CTRY_NAME'] == ctry_3) | (df['CTRY_NAME'] == ctry_4) | (df['CTRY_NAME'] == ctry_5)]\n",
    "    grouped = country.groupby(['CTRY_NAME'])['TRUSCI_IDX'].quantile(.75).reset_index().sort_values(by='TRUSCI_IDX', ascending=False).iloc[:,0].tolist()\n",
    "    return (country, grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_eu, west_eu_idx = trusci_idx_ctry(df, 'France', 'Germany', 'Switzerland', 'Netherlands', 'Belgium')\n",
    "east_eu, east_eu_idx = trusci_idx_ctry(df, 'Russia', 'Belarus', 'Ukraine', 'Poland', 'Romania')\n",
    "east_as, east_as_idx = trusci_idx_ctry(df, 'China', 'Japan', 'South Korea', 'Mongolia', 'Taiwan')\n",
    "south_am, south_am_idx = trusci_idx_ctry(df, 'Brazil', 'Peru', 'Venezuela', 'Argentina', 'Bolivia')\n",
    "sea, sea_idx = trusci_idx_ctry(df, 'Indonesia', 'Thailand', 'Malaysia', 'Philippines', 'Vietnam')\n",
    "north_af, north_ar_idx = trusci_idx_ctry(df, 'Egypt', 'Morocco', 'Algeria', 'Libya', 'Tunisia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2,ncols=3,figsize=(16,10))\n",
    "sns.boxplot(x='CTRY_NAME', y='TRUSCI_IDX', data=west_eu, ax=ax[0,0], order=west_eu_idx)\n",
    "ax[0,0].set_title('TRUSCI_IDX in Western Europe Countries')\n",
    "sns.boxplot(x='CTRY_NAME', y='TRUSCI_IDX', data=east_eu, ax=ax[0,1], order=east_eu_idx)\n",
    "ax[0,1].set_title('TRUSCI_IDX in Eastern Europe Countries')\n",
    "sns.boxplot(x='CTRY_NAME', y='TRUSCI_IDX', data=east_as, ax=ax[0,2], order=east_as_idx)\n",
    "ax[0,2].set_title('TRUSCI_IDX in East Asia Countries')\n",
    "sns.boxplot(x='CTRY_NAME', y='TRUSCI_IDX', data=south_am, ax=ax[1,0], order=south_am_idx)\n",
    "ax[1,0].set_title('TRUSCI_IDX in South America Countries')\n",
    "sns.boxplot(x='CTRY_NAME', y='TRUSCI_IDX', data=sea, ax=ax[1,1], order=sea_idx)\n",
    "ax[1,1].set_title('TRUSCI_IDX in Southeast Asia Countries')\n",
    "sns.boxplot(x='CTRY_NAME', y='TRUSCI_IDX', data=north_af, ax=ax[1,2], order=north_ar_idx)\n",
    "ax[1,2].set_title('TRUSCI_IDX in North Africa Countries')\n",
    "fig.savefig('/Users/Ming/Documents/GitHub/wellcome_dissertation/WellcomePy/py_image/trusci_idx_ctry.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}